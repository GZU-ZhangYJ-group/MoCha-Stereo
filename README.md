# MoCha-Stereo
[CVPR2024] The official implementation of "MoCha-Stereo: Motif Channel Attention Network for Stereo Matching".

> MoCha-Stereo: Motif Channel Attention Network for Stereo Matching <br>
> [Ziyang Chen](https://orcid.org/0000-0002-9361-0240)†, [Wei Long](https://orcid.org/0000-0002-4121-2742)†, [He Yao](https://orcid.org/0009-0002-4212-5023)†, [Yongjun Zhang](http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm)✳,[Bingshu Wang](https://teacher.nwpu.edu.cn/wangbingshu.html), [Yongbin Qin](http://cs.gzu.edu.cn/2021/1210/c17588a163794/page.htm), [Jia Wu](https://faculty.csu.edu.cn/jiawu/zh_CN/index.htm) <br>
> CVPR 2024 <br>
> Correspondence: ziyangchen2000@gmail.com; zyj6667@126.com✳ <br>
> Grateful to [Prof. Huamin Qu](http://www.huamin.org/), and anonymous reviewers for their comments on this work.

https://github.com/ZYangChen/MoCha-Stereo/assets/108012397/2ed414fe-d182-499b-895c-b5375ef51425


<strong>The code, checkpoints and camera-ready paper are still being prepared. They will be released when they are sorted out!</strong>
